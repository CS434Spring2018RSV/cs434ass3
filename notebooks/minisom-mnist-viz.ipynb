{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits visualization with the self-organizing map\n",
    "\n",
    "In this notebook, we'll use a classical visualization technique, the self-organizing map (SOM), to visualize MNIST digits.  Unfortunately, scikit-learn does not include the SOM algorithm, so we'll use an external package [minisom](https://github.com/JustGlowing/minisom).  This notebook is based on the minisom [digits example script](https://github.com/JustGlowing/minisom/blob/master/examples/example_digits.py).\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from minisom import MiniSom\n",
    "\n",
    "from pylab import text,show,cm,axis,figure,subplot,imshow,zeros\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the MNIST data. First time it downloads the data, which can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Let's inspect only 1024 first training samples in this notebook\n",
    "X = X_train[:1024]\n",
    "y = y_train[:1024]\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X:', X.shape)\n",
    "print('y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "As the SOM visualizations use a regular grid, we could use the whole MNIST training data to train the SOM.  Let's however use only a subset of the data to reduce training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xsize = 16\n",
    "ysize = 10\n",
    "epochs = 20\n",
    "\n",
    "t0 = time()\n",
    "som = MiniSom(xsize, ysize, 28*28 ,sigma=.5, learning_rate=0.2)\n",
    "som.train_random(X.reshape(-1,28*28), X.shape[0]*epochs)\n",
    "print('Time elapsed: %.2fs' % (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compute the nearest training sample for each SOM unit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "wmap = {}\n",
    "qerrors = np.empty((xsize,ysize))\n",
    "qerrors.fill(np.nan)\n",
    "for im,x in enumerate(X.reshape(-1,28*28)):\n",
    "    (i,j) = som.winner(x)\n",
    "    qe = np.linalg.norm(x-som.weights[i,j])\n",
    "    if np.isnan(qerrors[i,j]) or qe<qerrors[i,j]:\n",
    "        wmap[(i,j)] = im\n",
    "        qerrors[i,j] = qe\n",
    "print('Time elapsed: %.2fs' % (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We can visualize each SOM unit by the label of the nearest training sample.  The empty slots correspond to SOM units that have no associated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1)\n",
    "for j in range(ysize): # images mosaic\n",
    "\tfor i in range(xsize):\n",
    "\t\tif (i,j) in wmap:\n",
    "\t\t\ttext(i+.5, j+.5, str(y[wmap[(i,j)]]), \n",
    "                 color=cm.Dark2(y[wmap[(i,j)]]/9.), \n",
    "                 fontdict={'weight': 'bold', 'size': 11})\n",
    "ax = axis([0,som.weights.shape[0],0,som.weights.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, as we are working with image data, we can draw the actual nearest samples for each SOM unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(facecolor='white')\n",
    "cnt = 0\n",
    "for j in reversed(range(ysize)):\n",
    "\tfor i in range(xsize):\n",
    "\t\tsubplot(ysize,xsize,cnt+1,frameon=False, xticks=[], yticks=[])\n",
    "\t\tif (i,j) in wmap:\n",
    "\t\t\timshow(X[wmap[(i,j)]])\n",
    "\t\telse:\n",
    "\t\t\timshow(zeros((28,28)))\n",
    "\t\tcnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the SOM weights are also vectors in the input space, we can also draw the weights as images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(facecolor='white')\n",
    "cnt = 0\n",
    "for j in reversed(range(ysize)):\n",
    "\tfor i in range(xsize):\n",
    "\t\tsubplot(ysize,xsize,cnt+1,frameon=False, xticks=[], yticks=[])\n",
    "\t\timshow(som.weights[i,j].reshape(28,28))\n",
    "\t\tcnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
